{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "How_to_build_an_RNAseq_logistic_regression_classifier_R.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNLPB7/CX0Y2TklFt5LHk1R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    },
    "language_info": {
      "name": "R"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/isb-cgc/Community-Notebooks/blob/master/MachineLearning/How_to_build_an_RNAseq_logistic_regression_classifier_R.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-a-XwF2XfDSE"
      },
      "source": [
        "# How to build an RNA-seq logistic regression classifier in R\n",
        "Check out other notebooks at our [Community Notebooks Repository](https://github.com/isb-cgc/Community-Notebooks)!\n",
        "\n",
        "- **Title:** How to build an RNA-seq logistic regression classifier in R\n",
        "- **Author:** John Phan\n",
        "- **Created:** 2021-07-07\n",
        "- **Purpose:** Demonstrate a basic machine learning method to predict a cancer endpoint using gene expression data.\n",
        "- **URL:** https://github.com/isb-cgc/Community-Notebooks/blob/master/MachineLearning/How_to_build_an_RNAseq_logistic_regression_classifier_R.ipynb\n",
        "- **Note:** This example is based on the work published by [Bosquet et al.](https://molecular-cancer.biomedcentral.com/articles/10.1186/s12943-016-0548-9)\n",
        "\n",
        "This notebook demonstrates how to build a basic machine learning model to predict ovarian cancer treatment outcome. Ovarian cancer gene expression data is pulled from a BigQuery table and formatted using Pandas. The data is then split into training and testing sets to build and test a logistic regression classifier using the R SuperML library. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xs1wPDK8fPft"
      },
      "source": [
        "## Import Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLO2so7YeCIT"
      },
      "source": [
        "# BigQuery library\n",
        "if (!require(bigrquery)) {\n",
        "  print('Installing bigrquery package')\n",
        "  install.packages('bigrquery')\n",
        "  if (!require(bigrquery)) {\n",
        "    print('Cannot install bigrquery package')\n",
        "  }\n",
        "}\n",
        "\n",
        "# Tidyr library\n",
        "if (!require(tidyr)) {\n",
        "  print('Installing tidyr package')\n",
        "  install.packages('tidyr')\n",
        "  if (!require(tidyr)) {\n",
        "    print('Cannot install tidyr package')\n",
        "  }\n",
        "}\n",
        "\n",
        "# Caret library for machine learning\n",
        "if (!require(caret)) {\n",
        "  print('Installing caret package')\n",
        "  install.packages('caret')\n",
        "  if (!require(caret)) {\n",
        "    print('Cannot install caret package')\n",
        "  }\n",
        "}\n",
        "\n",
        "# SuperML library for machine learning\n",
        "if (!require(superml)) {\n",
        "  print('Installing superml package')\n",
        "  install.packages('superml')\n",
        "  if (!require(superml)) {\n",
        "    print('Cannot install superml package')\n",
        "  }\n",
        "}\n",
        "\n",
        "# glmnet library for generalized linear models\n",
        "if (!require(glmnet)) {\n",
        "  print('Installing glmnet package')\n",
        "  install.packages('glmnet')\n",
        "  if (!require(glmnet)) {\n",
        "    print('Cannot install glmnet package')\n",
        "  }\n",
        "}\n",
        "\n",
        "# pROC library for calculating AUC\n",
        "if (!require(pROC)) {\n",
        "  print('Installing pROC package')\n",
        "  install.packages('pROC')\n",
        "  if (!require(pROC)) {\n",
        "    print('Cannot install pROC package')\n",
        "  }\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dtg1ZI9YiB-U"
      },
      "source": [
        "## Authenticate to Access BigQuery\n",
        "\n",
        "Before using BigQuery, we need to get authorization for access to BigQuery and the Google Cloud. For more information see ['Quick Start Guide to ISB-CGC'](https://isb-cancer-genomics-cloud.readthedocs.io/en/latest/sections/HowToGetStartedonISB-CGC.html). R notebooks that use the BigRQuery library need the following work-around to authenticate. See the following link: https://gist.github.com/jobdiogenes/235620928c84e604c6e56211ccf681f0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMiBLLIQiFK0"
      },
      "source": [
        "# NOTE: this cell is only required if you're using Google Colab\n",
        "if (!require('R.utils')) {\n",
        "    print('Installing R.utils package')\n",
        "    install.packages(\"R.utils\")\n",
        "    if (!require('R.utils')) {\n",
        "        print('Cannot install R.utils package')\n",
        "    }\n",
        "}\n",
        "\n",
        "if (!require('httr')) {\n",
        "    print('Installing httr package')\n",
        "    install.pckages('httr')\n",
        "    if (!require('httr')) {\n",
        "        print('Cannot install httr package')\n",
        "    }\n",
        "}\n",
        "\n",
        "my_check <- function() {return(TRUE)}\n",
        "reassignInPackage(\"is_interactive\", pkgName = \"httr\", my_check) \n",
        "options(rlang_interactive=TRUE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpegJjvDiOUX"
      },
      "source": [
        "# Now authenticate to BQ. Be sure to select the BigQuery scope!\n",
        "bq_auth(use_oob = TRUE, cache = TRUE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIaqve5khiSK"
      },
      "source": [
        "## Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtYTGJIzhkn2"
      },
      "source": [
        "# set the google project that will be billed for this notebook's computations\n",
        "google_project <- 'google-project'\n",
        "\n",
        "# in this example, we'll be using the Ovarian cancer TCGA dataset\n",
        "cancer_type <- 'TCGA-OV'\n",
        "\n",
        "# gene expression data will be pulled from this BigQuery project\n",
        "bq_project <- 'isb-cgc-bq'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfX5Ght7ht-L"
      },
      "source": [
        "## Get Gene Expression Data from BigQuery Table\n",
        "\n",
        "Pull RNA-seq gene expression data from the TCGA RNA-seq BigQuery table and join it with the clinical data table to create a labeled data frame. In this example, we will label the samples based on therapy outcome. \"Complete Remission/Response\" will be labeled as \"1\" while all other therapy outcomes will be labeled as \"0\". This prepares the data for binary classification. \n",
        "\n",
        "Prediction modeling with RNA-seq data typically requires a feature selection step to reduce the dimensionality of the data before training a classifier. However, to simplify this example, we will use a pre-identified set of 33 genes (Bosquet et al. identified 34 genes, but PRSS2 and its aliases are not available in the hg38 RNA-seq data). \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37Kqwy2thxQw",
        "outputId": "c39a4f86-f246-471d-9abf-50539388d7ec"
      },
      "source": [
        "# Build query to retrieve gene expression data\n",
        "ge_query <- sprintf(\"\n",
        "  SELECT\n",
        "    ge.case_barcode AS sample,\n",
        "    labels.response_label AS label,\n",
        "    ge.gene_name AS gene_name,\n",
        "    -- Multiple samples may exist per case, take the max value\n",
        "    MAX(LOG(ge.fpkm_uq_unstranded+1)) AS gene_expression\n",
        "  FROM `%s.TCGA_versioned.RNAseq_hg38_gdc_r35` AS ge\n",
        "  INNER JOIN (\n",
        "    SELECT\n",
        "      *\n",
        "    FROM (\n",
        "      SELECT\n",
        "        case_barcode,\n",
        "        primary_therapy_outcome_success,\n",
        "        CASE\n",
        "          -- Complete Reponse    --> label as 1\n",
        "          -- All other responses --> label as 0\n",
        "          WHEN primary_therapy_outcome_success = 'Complete Remission/Response' THEN 1\n",
        "          WHEN (primary_therapy_outcome_success IN (\n",
        "            'Partial Remission/Response','Progressive Disease','Stable Disease'\n",
        "          )) THEN 0\n",
        "        END AS response_label\n",
        "        FROM `%s.TCGA_versioned.clinical_gdc_2019_06`\n",
        "        WHERE\n",
        "          project_short_name = '%s'\n",
        "          AND primary_therapy_outcome_success IS NOT NULL\n",
        "    )\n",
        "  ) labels\n",
        "  ON labels.case_barcode = ge.case_barcode\n",
        "  WHERE gene_name IN ( -- 33 Gene signature, leave out PRSS2 (aka TRYP2)\n",
        "    'RHOT1','MYO7A','ZBTB10','MATK','ST18','RPS23','GCNT1','DROSHA','NUAK1','CCPG1',\n",
        "    'PDGFD','KLRAP1','MTAP','RNF13','THBS1','MLX','FAP','TIMP3','PRSS1','SLC7A11',\n",
        "    'OLFML3','RPS20','MCM5','POLE','STEAP4','LRRC8D','WBP1L','ENTPD5','SYNE1','DPT',\n",
        "    'COPZ2','TRIO','PDPR'\n",
        "  )\n",
        "  GROUP BY sample, label, gene_name\n",
        "\", bq_project, bq_project, cancer_type)\n",
        "\n",
        "# Run the query\n",
        "ge_table <- bq_project_query(google_project, ge_query, quiet = TRUE)\n",
        "\n",
        "# Download the query result\n",
        "ge_data <- bq_table_download(ge_table, quiet = TRUE)\n",
        "\n",
        "# Show the dataframe\n",
        "str(ge_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tibble [8,712 × 4] (S3: tbl_df/tbl/data.frame)\n",
            " $ sample         : chr [1:8712] \"TCGA-24-1423\" \"TCGA-24-1563\" \"TCGA-25-1326\" \"TCGA-24-2036\" ...\n",
            " $ label          : int [1:8712] 1 1 0 1 1 1 1 1 0 1 ...\n",
            " $ gene_name      : chr [1:8712] \"POLE\" \"TRIO\" \"PDGFD\" \"POLE\" ...\n",
            " $ gene_expression: num [1:8712] 10.3 11.5 11.5 12 10.4 ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LTS_R8ViepV"
      },
      "source": [
        "## Reshape the Data\n",
        "\n",
        "The data pulled from BigQuery is formatted such that each row corresponds to a sample/gene combination. However, to use the data with scikit-learn, it is more convenient to reshape the data such that each row corresponds to a sample and each column corresponds to a gene. We'll use tidyr spread() function to pivot the data.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eldhMXBpihVA",
        "outputId": "65bbf79f-f6d0-4466-ca8e-cc048ef8b909"
      },
      "source": [
        "# Pivot the data frame with spread()\n",
        "ge_data_pivot <- spread(ge_data, key = \"gene_name\", value = \"gene_expression\")\n",
        "\n",
        "# Display pivoted data frame\n",
        "str(ge_data_pivot)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tibble [264 × 35] (S3: tbl_df/tbl/data.frame)\n",
            " $ sample : chr [1:264] \"TCGA-04-1331\" \"TCGA-04-1341\" \"TCGA-04-1343\" \"TCGA-04-1347\" ...\n",
            " $ label  : int [1:264] 1 1 0 1 0 0 0 0 1 1 ...\n",
            " $ CCPG1  : num [1:264] 10.5 10.6 10.9 10.7 10.2 ...\n",
            " $ COPZ2  : num [1:264] 11.1 12 12.6 11.1 10.4 ...\n",
            " $ DPT    : num [1:264] 10.01 10.22 11.12 9.65 6.81 ...\n",
            " $ DROSHA : num [1:264] 12.3 12.5 11.8 12.2 12.4 ...\n",
            " $ ENTPD5 : num [1:264] 10.78 10.35 10.41 9.97 11.52 ...\n",
            " $ FAP    : num [1:264] 10.28 9.94 10.75 9.04 0 ...\n",
            " $ GCNT1  : num [1:264] 12.59 9.11 9.79 10.76 10.62 ...\n",
            " $ KLRAP1 : num [1:264] 11.37 10.55 9.74 10.46 9.82 ...\n",
            " $ LRRC8D : num [1:264] 12.6 12.1 12.3 13 12.3 ...\n",
            " $ MATK   : num [1:264] 8.5 10.12 11.18 7.92 8.17 ...\n",
            " $ MCM5   : num [1:264] 12.7 12.3 12.6 12.6 11.8 ...\n",
            " $ MLX    : num [1:264] 11.8 12.9 12.2 12.5 11.7 ...\n",
            " $ MTAP   : num [1:264] 11.2 10.4 10.3 10.6 10.6 ...\n",
            " $ MYO7A  : num [1:264] 8.26 11.44 9.63 8.87 9.13 ...\n",
            " $ NUAK1  : num [1:264] 11.3 10.8 11.3 10.4 9.4 ...\n",
            " $ OLFML3 : num [1:264] 12.9 12.5 13.3 14.1 11.9 ...\n",
            " $ PDGFD  : num [1:264] 11.12 9.65 11.58 11.29 9.98 ...\n",
            " $ PDPR   : num [1:264] 11.4 10.9 11.2 11.8 11.5 ...\n",
            " $ POLE   : num [1:264] 11.9 11 11 11.2 10.5 ...\n",
            " $ PRSS1  : num [1:264] 12.4 12.4 11.8 12.5 11.7 ...\n",
            " $ RHOT1  : num [1:264] 11.3 11.4 11.2 11.8 11.7 ...\n",
            " $ RNF13  : num [1:264] 12.5 12 12.2 12.5 12.3 ...\n",
            " $ RPS20  : num [1:264] 16 17.7 16.9 17.6 17.7 ...\n",
            " $ RPS23  : num [1:264] 13.8 16.1 16.2 15.8 16.2 ...\n",
            " $ SLC7A11: num [1:264] 10.51 8.73 10.39 8.32 11.48 ...\n",
            " $ ST18   : num [1:264] 5.03 0 6.02 4.84 5.02 ...\n",
            " $ STEAP4 : num [1:264] 9.41 8.16 10.09 7.72 5.26 ...\n",
            " $ SYNE1  : num [1:264] 9.05 8.48 8.86 8.53 7.52 ...\n",
            " $ THBS1  : num [1:264] 12.3 12.4 13.1 12.3 11 ...\n",
            " $ TIMP3  : num [1:264] 10.27 9.22 11.06 10.37 10.15 ...\n",
            " $ TRIO   : num [1:264] 11.8 11.5 11.3 11.3 11.5 ...\n",
            " $ WBP1L  : num [1:264] 12.7 12.7 13.1 13.1 13.6 ...\n",
            " $ ZBTB10 : num [1:264] 11.9 11.7 11.5 11.1 12.6 ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYgr_mK8itet"
      },
      "source": [
        "## Prepare the Data for Prediction Modeling\n",
        "\n",
        "Prepare the data by splitting it into training and testing sets, and scaling the data. It is important that prediction models are tested on samples that are independent from the training samples in order to accurately estimate performance. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKc4PGyMiuhe"
      },
      "source": [
        "# remove the sample names column from the data frame\n",
        "ge_data_pivot_nosample <- subset(ge_data_pivot, select=-c(sample))\n",
        "\n",
        "# use the caret createDataPartition function to create a balanced split of the data into train and test sets\n",
        "set.seed(10)\n",
        "train_rows = createDataPartition(ge_data_pivot_nosample$label, p=0.5, list=FALSE, times=1)\n",
        "train_data <- ge_data_pivot_nosample[train_rows,]\n",
        "test_data <- ge_data_pivot_nosample[-train_rows,]\n",
        "\n",
        "# move labels to their own variables\n",
        "train_y <- train_data$label\n",
        "test_y <- test_data$label\n",
        "\n",
        "# use caret's preProcess function to scale the data to 0 mean and unit variance\n",
        "pre_proc_vals <- preProcess(subset(train_data, select=-c(label)), method=c('center', 'scale'))\n",
        "train_x <- predict(pre_proc_vals, subset(train_data, select=-c(label)))\n",
        "test_x <- predict(pre_proc_vals, subset(test_data, select=-c(label)))\n",
        "\n",
        "# recombine the data and labels\n",
        "train_data <- train_x\n",
        "train_data$label <- train_y\n",
        "test_data <- test_x\n",
        "test_data$label <- test_y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8ZGWd-Zi4nv"
      },
      "source": [
        "## Train and Test the Prediction Model\n",
        "\n",
        "We use a simple logistic regression classifier implemented in the \"SuperML\" R package. SuperML was designed to be very similar to the Python scikit-learn package for machine learning. More information about the SuperML can be found [here](https://rdrr.io/cran/superml/f/vignettes/introduction.Rmd). After training the classifier using the \"fit\" function, we use the \"predict\" function to predict a decision value for each sample in the test dataset. Because the dataset may not be balanced in terms of the number of samples in each class, we use AUC, or Area Under the ROC curve, to assess prediction performance. The decision values are used to calculate the AUC, with higher AUC values indicating better prediction performance. An AUC of 1 indicates perfect prediction. More information about accuracy, AUC, and other classification performance metrics can be found in the [Google Machine Learning crash course](https://developers.google.com/machine-learning/crash-course/classification/video-lecture). Read about AUC [here](https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc).  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TeMLZJ4Ki8uO",
        "outputId": "8d3ebfa5-f5e3-432c-bc7a-577f12e2525f"
      },
      "source": [
        "# Create an instance of the model using the superml Linear Model trainer and \n",
        "# the binomial family for logistic regression classification\n",
        "model <- LMTrainer$new(family = 'binomial')\n",
        "\n",
        "# Fit the model with the training data\n",
        "model$fit(X=train_data, y='label')\n",
        "summary(model$model)\n",
        "\n",
        "# Predict samples in the test data\n",
        "predictions <- model$predict(df=test_data)\n",
        "\n",
        "# Evaluate performance using AUC\n",
        "auc_value <- auc(test_data$label, predictions)\n",
        "print(sprintf('Prediction Performance (AUC): %s', auc_value))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Call:\n",
              "stats::glm(formula = f, family = self$family, data = X, weights = self$weights)\n",
              "\n",
              "Deviance Residuals: \n",
              "    Min       1Q   Median       3Q      Max  \n",
              "-2.4077  -0.8051   0.3323   0.7529   1.7680  \n",
              "\n",
              "Coefficients:\n",
              "            Estimate Std. Error z value Pr(>|z|)    \n",
              "(Intercept)  1.37915    0.29223   4.719 2.37e-06 ***\n",
              "CCPG1       -0.10863    0.40005  -0.272   0.7860    \n",
              "COPZ2        0.22430    0.56831   0.395   0.6931    \n",
              "DPT         -0.34782    0.51897  -0.670   0.5027    \n",
              "DROSHA       0.12363    0.36257   0.341   0.7331    \n",
              "ENTPD5       0.26706    0.34229   0.780   0.4353    \n",
              "FAP          0.17426    0.64122   0.272   0.7858    \n",
              "GCNT1        0.27284    0.32335   0.844   0.3988    \n",
              "KLRAP1      -0.01840    0.33708  -0.055   0.9565    \n",
              "LRRC8D       0.49565    0.30413   1.630   0.1032    \n",
              "MATK        -0.38799    0.33643  -1.153   0.2488    \n",
              "MCM5        -0.16778    0.36915  -0.455   0.6495    \n",
              "MLX          0.71550    0.45484   1.573   0.1157    \n",
              "MTAP         0.15597    0.28732   0.543   0.5872    \n",
              "MYO7A        0.04331    0.33216   0.130   0.8963    \n",
              "NUAK1       -0.42736    0.39572  -1.080   0.2802    \n",
              "OLFML3      -0.10515    0.39579  -0.266   0.7905    \n",
              "PDGFD        0.07814    0.38581   0.203   0.8395    \n",
              "PDPR         0.47315    0.35067   1.349   0.1772    \n",
              "POLE         0.73512    0.47320   1.553   0.1203    \n",
              "PRSS1       -0.26930    0.30626  -0.879   0.3792    \n",
              "RHOT1       -0.64278    0.34833  -1.845   0.0650 .  \n",
              "RNF13        0.64850    0.36796   1.762   0.0780 .  \n",
              "RPS20        1.00543    0.48870   2.057   0.0397 *  \n",
              "RPS23       -0.10848    0.42856  -0.253   0.8002    \n",
              "SLC7A11      0.36360    0.29058   1.251   0.2108    \n",
              "ST18        -0.41047    0.34837  -1.178   0.2387    \n",
              "STEAP4      -0.06865    0.30454  -0.225   0.8217    \n",
              "SYNE1       -0.01625    0.38984  -0.042   0.9668    \n",
              "THBS1        0.64406    0.54842   1.174   0.2402    \n",
              "TIMP3       -0.18786    0.47919  -0.392   0.6950    \n",
              "TRIO         0.30284    0.39266   0.771   0.4406    \n",
              "WBP1L       -0.51022    0.33678  -1.515   0.1298    \n",
              "ZBTB10       0.24819    0.31424   0.790   0.4296    \n",
              "---\n",
              "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
              "\n",
              "(Dispersion parameter for binomial family taken to be 1)\n",
              "\n",
              "    Null deviance: 160.24  on 131  degrees of freedom\n",
              "Residual deviance: 119.14  on  98  degrees of freedom\n",
              "AIC: 187.14\n",
              "\n",
              "Number of Fisher Scoring iterations: 5\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting levels: control = 0, case = 1\n",
            "\n",
            "Setting direction: controls < cases\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] \"Prediction Performance (AUC): 0.713391739674593\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hBZn6lFlbMV"
      },
      "source": [
        "## Evaluate Prediction Performance\n",
        "\n",
        "The prediction performance AUC of 0.71 is within the performance range (0.7 to 0.8) of the models developed by Bosquet et al. Note that if the \"random_state\" value is changed in the train/test split step, prediction performance will vary. Thus, a better method for assessing performance would be to generate multiple permutations of train/test datasets, calculate prediction performance for each permutation, and report the mean and standard deviation of AUC.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82LJMPQVkj6W"
      },
      "source": [
        "num_iters <- 100\n",
        "auc_vals <- c()\n",
        "\n",
        "for (i in 1:num_iters) {\n",
        "  # use the caret createDataPartition function to create a balanced split of the data into train and test sets\n",
        "  train_rows = createDataPartition(ge_data_pivot_nosample$label, p=0.5, list=FALSE, times=1)\n",
        "  train_data <- ge_data_pivot_nosample[train_rows,]\n",
        "  test_data <- ge_data_pivot_nosample[-train_rows,]\n",
        "\n",
        "  # move labels to their own variables\n",
        "  train_y <- train_data$label\n",
        "  test_y <- test_data$label\n",
        "\n",
        "  # use caret's preProcess function to scale the data to 0 mean and unit variance\n",
        "  pre_proc_vals <- preProcess(subset(train_data, select=-c(label)), method=c('center', 'scale'))\n",
        "  train_x <- predict(pre_proc_vals, subset(train_data, select=-c(label)))\n",
        "  test_x <- predict(pre_proc_vals, subset(test_data, select=-c(label)))\n",
        "\n",
        "  # recombine the data and labels\n",
        "  train_data <- train_x\n",
        "  train_data$label <- train_y\n",
        "  test_data <- test_x\n",
        "  test_data$label <- test_y\n",
        "\n",
        "  # Create an instance of the model using the superml Linear Model trainer and \n",
        "  # the binomial family for logistic regression classification\n",
        "  model <- LMTrainer$new(family = 'binomial')\n",
        "\n",
        "  # Fit the model with the training data\n",
        "  model$fit(X=train_data, y='label')\n",
        "\n",
        "  # Predict samples in the test data\n",
        "  predictions <- model$predict(df=test_data)\n",
        "\n",
        "  # Evaluate performance using AUC\n",
        "  auc_val <- auc(test_data$label, predictions)\n",
        "  auc_vals[i] <- auc_val\n",
        "}\n",
        "\n",
        "print(sprintf('AUC Mean: %s', mean(auc_vals)))\n",
        "print(sprintf('AUC Standard Deviation: %s', sd(auc_vals)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxV9vK-BmMog"
      },
      "source": [
        "## Visualize and Interpret Results\n",
        "\n",
        "We can use data visualization to help interpret the classifier's performance. Although our initial prediction result was 0.71, the average prediction result over several random permutations of the data is actually below 0.7, with a range spanning approximately 0.6 to 0.7. An AUC of 0.7 can be interpreted as a 70% chance that the classifier's prediction (i.e., \"Complete Remission/Response\" or not) is correct. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "U99DUlIGmQKt",
        "outputId": "ee636ea6-65b6-42d0-c800-49a866b7e442"
      },
      "source": [
        "# use a boxplot to visualize the AUC results\n",
        "boxplot(auc_vals, ylab='Logistic Regression', xlab='AUC', horizontal=TRUE, ylim=c(0, 1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAC3FBMVEUAAAABAQECAgIDAwME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\ngP8Pd7LeuyuuOAUAAAAASUVORK5CYII=",
            "text/plain": [
              "plot without title"
            ]
          },
          "metadata": {
            "image/png": {
              "width": 420,
              "height": 420
            }
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1J3LqC21mWWJ"
      },
      "source": [
        "## Next Steps\n",
        "\n",
        "The model trained and stored in the \"model\" variable can now be used to predict therapeutic outcome of future RNA-seq ovarian cancer samples. If the model has been trained to generalize well to the problem of predicting Ovarian cancer therapeutic outcome, we would expect that future predictions would yield up to a 70% probability of being correct. However, an inherent problem with estimating machine learning performance is its dependence on the data. Thus, if future RNA-seq samples differ from the training data (e.g., different biological population, different sequencing method or instrument, or different data normalization method), we cannot make any assumptions about the model's prediction of those samples. In addition, if the testing data in our original assessment is different from the training data, then our performance estimation of 0.7 AUC may not be reliable. See [Zhang et al.](https://academic.oup.com/nargab/article/2/3/lqaa078/5909519) for more information about RNA-seq batch effects. \n",
        "\n",
        "As an example, suppose that we have a future sample to predict:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pt4X0LWgmZvh",
        "outputId": "b4254dfa-7ef6-43f9-9d60-61e4ddd3d478"
      },
      "source": [
        "# For this example, we'll just take a single sample out of our previous test\n",
        "# dataset. However, in practical applications, the future sample usually comes\n",
        "# from new, independent datasets. \n",
        "future_sample = test_data[10,]\n",
        "\n",
        "# Predict the therapeutic outcome of the future sample using the \"predict\" \n",
        "# function, which will give us a label of either 0 or 1\n",
        "sample_prediction <- model$predict(df=future_sample)\n",
        "\n",
        "# The predict function actually returns a decision value, which needs to be\n",
        "# thresholded to obtain a prediction label. In this case the threshold is 0.5 and\n",
        "# decision values >0.5 are labeled \"1\" while decision values <=0.5 are \n",
        "# labeled \"0\".\n",
        "prediction_label <- if (sample_prediction > 0.5) 1 else 0\n",
        "print(sprintf(\"Decision value: %s\", sample_prediction))\n",
        "print(sprintf(\"Prediction label: %s\", prediction_label))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] \"Decision value: 0.578681841679563\"\n",
            "[1] \"Prediction label: 1\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3uxItsPmk5p"
      },
      "source": [
        "A predicted label of \"1\" means that this future sample is predicted to have \"Complete Remission/Response\", while a predicted label of \"0\" means that this future sample is predicted to have \"No Response\" to therapy. This prediction process can be repeated for any number of future samples."
      ]
    }
  ]
}
