{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "How_to_build_an_RNAseq_logistic_regression_classifier_with_BigQuery_ML.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOxrAPTgk6Z3w2bv7fCVIoN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/isb-cgc/Community-Notebooks/blob/master/MachineLearning/How_to_build_an_RNAseq_logistic_regression_classifier_with_BigQuery_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgwv4lK5V8Zc"
      },
      "source": [
        "# How to build an RNA-seq logistic regression classifier with BigQuery ML\n",
        "Check out other notebooks at our [Community Notebooks Repository](https://github.com/isb-cgc/Community-Notebooks)!\n",
        "\n",
        "- **Title:** How to build an RNA-seq logistic regression classifier with BigQuery ML\n",
        "- **Author:** John Phan\n",
        "- **Created:** 2021-07-19\n",
        "- **Purpose:** Demonstrate use of BigQuery ML to predict a cancer endpoint using gene expression data.\n",
        "- **URL:** https://github.com/isb-cgc/Community-Notebooks/blob/master/MachineLearning/How_to_build_an_RNAseq_logistic_regression_classifier_with_BigQuery_ML.ipynb\n",
        "- **Note:** This example is based on the work published by [Bosquet et al.](https://molecular-cancer.biomedcentral.com/articles/10.1186/s12943-016-0548-9)\n",
        "\n",
        "\n",
        "This notebook builds upon the [scikit-learn notebook](https://github.com/isb-cgc/Community-Notebooks/blob/master/MachineLearning/How_to_build_an_RNAseq_logistic_regression_classifier.ipynb) and demonstrates how to build a machine learning model using BigQuery ML to predict ovarian cancer treatment outcome. BigQuery is used to create a temporary data table that contains both training and testing data. These datasets are then used to fit and evaluate a Logistic Regression classifier. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zVfEL8i8__O"
      },
      "source": [
        "# Import Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNlADvO-gken"
      },
      "source": [
        "# GCP libraries\n",
        "from google.cloud import bigquery\n",
        "from google.colab import auth"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBHnu8bZDEcE"
      },
      "source": [
        "## Authenticate\n",
        "\n",
        "Before using BigQuery, we need to get authorization for access to BigQuery and the Google Cloud. For more information see ['Quick Start Guide to ISB-CGC'](https://isb-cancer-genomics-cloud.readthedocs.io/en/latest/sections/HowToGetStartedonISB-CGC.html). Alternative authentication methods can be found [here](https://googleapis.dev/python/google-api-core/latest/auth.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6BEFHj2dd5a"
      },
      "source": [
        "# if you're using Google Colab, authenticate to gcloud with the following\n",
        "auth.authenticate_user()\n",
        "\n",
        "# alternatively, use the gcloud SDK\n",
        "#!gcloud auth application-default login"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWuECMsRptWJ"
      },
      "source": [
        "## Parameters\n",
        "\n",
        "Customize the following parameters based on your notebook, execution environment, or project. BigQuery ML must create and store classification models, so be sure that you have write access to the locations stored in the \"bq_dataset\" and \"bq_project\" variables. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veP6gPatu2iW"
      },
      "source": [
        "# set the google project that will be billed for this notebook's computations\n",
        "google_project = 'google-project' ## CHANGE ME\n",
        "\n",
        "# bq project for storing ML model\n",
        "bq_project = 'bq-project' ## CHANGE ME\n",
        "\n",
        "# bq dataset for storing ML model\n",
        "bq_dataset = 'scratch' ## CHANGE ME\n",
        "\n",
        "# name of temporary table for data\n",
        "bq_tmp_table = 'tmp_data'\n",
        "\n",
        "# name of ML model\n",
        "bq_ml_model = 'tcga_ov_therapy_ml_lr_model'\n",
        "\n",
        "# in this example, we'll be using the Ovarian cancer TCGA dataset\n",
        "cancer_type = 'TCGA-OV'\n",
        "\n",
        "# genes used for prediction model, taken from Bosquet et al.\n",
        "genes = \"'RHOT1','MYO7A','ZBTB10','MATK','ST18','RPS23','GCNT1','DROSHA','NUAK1','CCPG1',\\\n",
        "'PDGFD','KLRAP1','MTAP','RNF13','THBS1','MLX','FAP','TIMP3','PRSS1','SLC7A11',\\\n",
        "'OLFML3','RPS20','MCM5','POLE','STEAP4','LRRC8D','WBP1L','ENTPD5','SYNE1','DPT',\\\n",
        "'COPZ2','TRIO','PDPR'\"\n",
        "\n",
        "# clinical data table\n",
        "clinical_table = 'isb-cgc-bq.TCGA_versioned.clinical_gdc_2019_06'\n",
        "\n",
        "# RNA seq data table\n",
        "rnaseq_table = 'isb-cgc-bq.TCGA.RNAseq_hg38_gdc_current'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6zTODbDq3g9"
      },
      "source": [
        "## BigQuery Client\n",
        "\n",
        "Create the BigQuery client."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNkfSXedwzbC"
      },
      "source": [
        "# Create a client to access the data within BigQuery\n",
        "client = bigquery.Client(google_project)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4jPuJnUYkju"
      },
      "source": [
        "## Create a Table with a Subset of the Gene Expression Data\n",
        "\n",
        "Pull RNA-seq gene expression data from the TCGA RNA-seq BigQuery table, join it with clinical labels, and pivot the table so that it can be used with BigQuery ML. In this example, we will label the samples based on therapy outcome. \"Complete Remission/Response\" will be labeled as \"1\" while all other therapy outcomes will be labeled as \"0\". This prepares the data for binary classification. \n",
        "\n",
        "Prediction modeling with RNA-seq data typically requires a feature selection step to reduce the dimensionality of the data before training a classifier. However, to simplify this example, we will use a pre-identified set of 33 genes (Bosquet et al. identified 34 genes, but PRSS2 and its aliases are not available in the hg38 RNA-seq data). \n",
        "\n",
        "Creation of a BQ table with only the data of interest reduces the size of the data passed to BQ ML and can significantly reduce the cost of running BQ ML queries. This query also randomly splits the dataset into \"training\" and \"testing\" sets using the \"FARM_FINGERPRINT\" hash function in BigQuery. \"FARM_FINGERPRINT\" generates an integer from the input string. More information can be found [here](https://cloud.google.com/bigquery/docs/reference/standard-sql/hash_functions)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYKK8nT7Rzpa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba8b8162-a478-4b80-95b4-4bdebb0310b3"
      },
      "source": [
        "tmp_table_query = client.query((\"\"\"\n",
        "  BEGIN\n",
        "  CREATE OR REPLACE TABLE `{bq_project}.{bq_dataset}.{bq_tmp_table}` AS\n",
        "  SELECT * FROM (\n",
        "    SELECT\n",
        "      labels.case_barcode as sample,\n",
        "      labels.data_partition as data_partition,\n",
        "      labels.response_label AS label,\n",
        "      ge.gene_name AS gene_name,\n",
        "      -- Multiple samples may exist per case, take the max value\n",
        "      MAX(LOG(ge.HTSeq__FPKM_UQ+1)) AS gene_expression\n",
        "    FROM `{rnaseq_table}` AS ge\n",
        "    INNER JOIN (\n",
        "      SELECT\n",
        "        *\n",
        "      FROM (\n",
        "        SELECT\n",
        "          case_barcode,\n",
        "          primary_therapy_outcome_success,\n",
        "          CASE\n",
        "            -- Complete Reponse    --> label as 1\n",
        "            -- All other responses --> label as 0\n",
        "            WHEN primary_therapy_outcome_success = 'Complete Remission/Response' THEN 1\n",
        "            WHEN (primary_therapy_outcome_success IN (\n",
        "              'Partial Remission/Response','Progressive Disease','Stable Disease'\n",
        "            )) THEN 0\n",
        "          END AS response_label,\n",
        "          CASE \n",
        "            WHEN MOD(ABS(FARM_FINGERPRINT(case_barcode)), 10) < 5 THEN 'training'\n",
        "            WHEN MOD(ABS(FARM_FINGERPRINT(case_barcode)), 10) >= 5 THEN 'testing'\n",
        "          END AS data_partition\n",
        "          FROM `{clinical_table}`\n",
        "          WHERE\n",
        "            project_short_name = '{cancer_type}'\n",
        "            AND primary_therapy_outcome_success IS NOT NULL\n",
        "      )\n",
        "    ) labels\n",
        "    ON labels.case_barcode = ge.case_barcode\n",
        "    WHERE gene_name IN ({genes})\n",
        "    GROUP BY sample, label, data_partition, gene_name\n",
        "  )\n",
        "  PIVOT (\n",
        "    MAX(gene_expression) FOR gene_name IN ({genes})\n",
        "  );\n",
        "  END;\n",
        "\"\"\").format(\n",
        "  bq_project=bq_project,\n",
        "  bq_dataset=bq_dataset,\n",
        "  bq_tmp_table=bq_tmp_table,\n",
        "  rnaseq_table=rnaseq_table,\n",
        "  clinical_table=clinical_table,\n",
        "  cancer_type=cancer_type,\n",
        "  genes=genes\n",
        ")).result()\n",
        "\n",
        "print(tmp_table_query)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<google.cloud.bigquery.table._EmptyRowIterator object at 0x7f3894001250>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQe3PFfBBh-c"
      },
      "source": [
        "Let's take a look at this subset table. The data has been pivoted such that each of the 33 genes is available as a column that can be \"SELECTED\" in a query. In addition, the \"label\" and \"data_partition\" columns simplify data handling for classifier training and evaluation.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1zf84HElBbh_",
        "outputId": "3396e1b7-47fc-43d7-a110-312bb0cb67f4"
      },
      "source": [
        "tmp_table_data = client.query((\"\"\"\n",
        "  SELECT\n",
        "    * --usually not recommended to use *, but in this case, we want to see all of the 33 genes\n",
        "  FROM `{bq_project}.{bq_dataset}.{bq_tmp_table}`\n",
        "\"\"\").format(\n",
        "    bq_project=bq_project,\n",
        "    bq_dataset=bq_dataset,\n",
        "    bq_tmp_table=bq_tmp_table\n",
        ")).result().to_dataframe()\n",
        "\n",
        "print(tmp_table_data.info())\n",
        "tmp_table_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 264 entries, 0 to 263\n",
            "Data columns (total 36 columns):\n",
            " #   Column          Non-Null Count  Dtype  \n",
            "---  ------          --------------  -----  \n",
            " 0   sample          264 non-null    object \n",
            " 1   data_partition  264 non-null    object \n",
            " 2   label           264 non-null    int64  \n",
            " 3   RHOT1           264 non-null    float64\n",
            " 4   MYO7A           264 non-null    float64\n",
            " 5   ZBTB10          264 non-null    float64\n",
            " 6   MATK            264 non-null    float64\n",
            " 7   ST18            264 non-null    float64\n",
            " 8   RPS23           264 non-null    float64\n",
            " 9   GCNT1           264 non-null    float64\n",
            " 10  DROSHA          264 non-null    float64\n",
            " 11  NUAK1           264 non-null    float64\n",
            " 12  CCPG1           264 non-null    float64\n",
            " 13  PDGFD           264 non-null    float64\n",
            " 14  KLRAP1          264 non-null    float64\n",
            " 15  MTAP            264 non-null    float64\n",
            " 16  RNF13           264 non-null    float64\n",
            " 17  THBS1           264 non-null    float64\n",
            " 18  MLX             264 non-null    float64\n",
            " 19  FAP             264 non-null    float64\n",
            " 20  TIMP3           264 non-null    float64\n",
            " 21  PRSS1           264 non-null    float64\n",
            " 22  SLC7A11         264 non-null    float64\n",
            " 23  OLFML3          264 non-null    float64\n",
            " 24  RPS20           264 non-null    float64\n",
            " 25  MCM5            264 non-null    float64\n",
            " 26  POLE            264 non-null    float64\n",
            " 27  STEAP4          264 non-null    float64\n",
            " 28  LRRC8D          264 non-null    float64\n",
            " 29  WBP1L           264 non-null    float64\n",
            " 30  ENTPD5          264 non-null    float64\n",
            " 31  SYNE1           264 non-null    float64\n",
            " 32  DPT             264 non-null    float64\n",
            " 33  COPZ2           264 non-null    float64\n",
            " 34  TRIO            264 non-null    float64\n",
            " 35  PDPR            264 non-null    float64\n",
            "dtypes: float64(33), int64(1), object(2)\n",
            "memory usage: 74.4+ KB\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sample</th>\n",
              "      <th>data_partition</th>\n",
              "      <th>label</th>\n",
              "      <th>RHOT1</th>\n",
              "      <th>MYO7A</th>\n",
              "      <th>ZBTB10</th>\n",
              "      <th>MATK</th>\n",
              "      <th>ST18</th>\n",
              "      <th>RPS23</th>\n",
              "      <th>GCNT1</th>\n",
              "      <th>DROSHA</th>\n",
              "      <th>NUAK1</th>\n",
              "      <th>CCPG1</th>\n",
              "      <th>PDGFD</th>\n",
              "      <th>KLRAP1</th>\n",
              "      <th>MTAP</th>\n",
              "      <th>RNF13</th>\n",
              "      <th>THBS1</th>\n",
              "      <th>MLX</th>\n",
              "      <th>FAP</th>\n",
              "      <th>TIMP3</th>\n",
              "      <th>PRSS1</th>\n",
              "      <th>SLC7A11</th>\n",
              "      <th>OLFML3</th>\n",
              "      <th>RPS20</th>\n",
              "      <th>MCM5</th>\n",
              "      <th>POLE</th>\n",
              "      <th>STEAP4</th>\n",
              "      <th>LRRC8D</th>\n",
              "      <th>WBP1L</th>\n",
              "      <th>ENTPD5</th>\n",
              "      <th>SYNE1</th>\n",
              "      <th>DPT</th>\n",
              "      <th>COPZ2</th>\n",
              "      <th>TRIO</th>\n",
              "      <th>PDPR</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TCGA-25-2399</td>\n",
              "      <td>testing</td>\n",
              "      <td>0</td>\n",
              "      <td>11.218927</td>\n",
              "      <td>10.593754</td>\n",
              "      <td>11.803524</td>\n",
              "      <td>9.698836</td>\n",
              "      <td>5.956653</td>\n",
              "      <td>14.401808</td>\n",
              "      <td>10.929323</td>\n",
              "      <td>12.712570</td>\n",
              "      <td>11.296218</td>\n",
              "      <td>10.285688</td>\n",
              "      <td>10.772224</td>\n",
              "      <td>10.099598</td>\n",
              "      <td>11.180881</td>\n",
              "      <td>12.446402</td>\n",
              "      <td>13.861651</td>\n",
              "      <td>12.302866</td>\n",
              "      <td>11.066391</td>\n",
              "      <td>11.269558</td>\n",
              "      <td>9.734049</td>\n",
              "      <td>11.243680</td>\n",
              "      <td>13.520391</td>\n",
              "      <td>15.814351</td>\n",
              "      <td>12.147187</td>\n",
              "      <td>11.190978</td>\n",
              "      <td>9.587428</td>\n",
              "      <td>12.406302</td>\n",
              "      <td>12.714173</td>\n",
              "      <td>11.296678</td>\n",
              "      <td>9.197123</td>\n",
              "      <td>10.326844</td>\n",
              "      <td>11.506841</td>\n",
              "      <td>12.260439</td>\n",
              "      <td>11.589751</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TCGA-36-1569</td>\n",
              "      <td>testing</td>\n",
              "      <td>0</td>\n",
              "      <td>11.878180</td>\n",
              "      <td>9.587484</td>\n",
              "      <td>12.164811</td>\n",
              "      <td>11.734965</td>\n",
              "      <td>5.994159</td>\n",
              "      <td>15.347050</td>\n",
              "      <td>10.687141</td>\n",
              "      <td>12.119207</td>\n",
              "      <td>12.033689</td>\n",
              "      <td>10.596642</td>\n",
              "      <td>12.058906</td>\n",
              "      <td>9.588679</td>\n",
              "      <td>10.708653</td>\n",
              "      <td>12.645890</td>\n",
              "      <td>13.552602</td>\n",
              "      <td>12.633329</td>\n",
              "      <td>11.461555</td>\n",
              "      <td>12.872430</td>\n",
              "      <td>10.501176</td>\n",
              "      <td>10.647165</td>\n",
              "      <td>14.032178</td>\n",
              "      <td>16.020236</td>\n",
              "      <td>12.035344</td>\n",
              "      <td>11.001714</td>\n",
              "      <td>9.580656</td>\n",
              "      <td>11.963750</td>\n",
              "      <td>13.782162</td>\n",
              "      <td>10.770550</td>\n",
              "      <td>9.732567</td>\n",
              "      <td>11.786655</td>\n",
              "      <td>12.154511</td>\n",
              "      <td>12.212926</td>\n",
              "      <td>11.787660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TCGA-25-1316</td>\n",
              "      <td>testing</td>\n",
              "      <td>0</td>\n",
              "      <td>11.617410</td>\n",
              "      <td>9.906155</td>\n",
              "      <td>11.821766</td>\n",
              "      <td>8.731946</td>\n",
              "      <td>5.019471</td>\n",
              "      <td>16.034114</td>\n",
              "      <td>10.456743</td>\n",
              "      <td>12.487554</td>\n",
              "      <td>10.511889</td>\n",
              "      <td>10.506308</td>\n",
              "      <td>12.279526</td>\n",
              "      <td>9.630796</td>\n",
              "      <td>10.804051</td>\n",
              "      <td>12.414362</td>\n",
              "      <td>11.633886</td>\n",
              "      <td>12.054653</td>\n",
              "      <td>8.549910</td>\n",
              "      <td>11.698269</td>\n",
              "      <td>6.389008</td>\n",
              "      <td>10.339602</td>\n",
              "      <td>13.493717</td>\n",
              "      <td>16.862480</td>\n",
              "      <td>12.713662</td>\n",
              "      <td>11.535904</td>\n",
              "      <td>7.052493</td>\n",
              "      <td>11.656133</td>\n",
              "      <td>13.290609</td>\n",
              "      <td>10.595292</td>\n",
              "      <td>9.338195</td>\n",
              "      <td>9.510685</td>\n",
              "      <td>10.488821</td>\n",
              "      <td>11.567196</td>\n",
              "      <td>11.550038</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TCGA-23-1109</td>\n",
              "      <td>testing</td>\n",
              "      <td>0</td>\n",
              "      <td>11.235278</td>\n",
              "      <td>9.680673</td>\n",
              "      <td>12.364107</td>\n",
              "      <td>9.137896</td>\n",
              "      <td>5.365037</td>\n",
              "      <td>14.565009</td>\n",
              "      <td>10.257964</td>\n",
              "      <td>12.090694</td>\n",
              "      <td>11.171379</td>\n",
              "      <td>9.682388</td>\n",
              "      <td>11.533465</td>\n",
              "      <td>10.434751</td>\n",
              "      <td>10.749742</td>\n",
              "      <td>12.543119</td>\n",
              "      <td>13.067357</td>\n",
              "      <td>12.133442</td>\n",
              "      <td>10.446814</td>\n",
              "      <td>12.173429</td>\n",
              "      <td>11.444376</td>\n",
              "      <td>10.210248</td>\n",
              "      <td>12.848341</td>\n",
              "      <td>16.704705</td>\n",
              "      <td>12.694445</td>\n",
              "      <td>11.392936</td>\n",
              "      <td>10.073326</td>\n",
              "      <td>12.297649</td>\n",
              "      <td>12.804440</td>\n",
              "      <td>10.436196</td>\n",
              "      <td>9.563981</td>\n",
              "      <td>10.485045</td>\n",
              "      <td>12.222601</td>\n",
              "      <td>11.504207</td>\n",
              "      <td>11.931388</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TCGA-24-2293</td>\n",
              "      <td>testing</td>\n",
              "      <td>0</td>\n",
              "      <td>11.517847</td>\n",
              "      <td>10.202071</td>\n",
              "      <td>11.412929</td>\n",
              "      <td>9.605096</td>\n",
              "      <td>6.916302</td>\n",
              "      <td>14.294266</td>\n",
              "      <td>11.047738</td>\n",
              "      <td>12.449760</td>\n",
              "      <td>13.146952</td>\n",
              "      <td>10.346396</td>\n",
              "      <td>11.989061</td>\n",
              "      <td>10.152489</td>\n",
              "      <td>10.698240</td>\n",
              "      <td>12.501491</td>\n",
              "      <td>14.640638</td>\n",
              "      <td>12.359135</td>\n",
              "      <td>12.150775</td>\n",
              "      <td>12.036429</td>\n",
              "      <td>9.374763</td>\n",
              "      <td>8.660519</td>\n",
              "      <td>14.609033</td>\n",
              "      <td>15.541052</td>\n",
              "      <td>12.234289</td>\n",
              "      <td>11.034500</td>\n",
              "      <td>10.918893</td>\n",
              "      <td>12.176423</td>\n",
              "      <td>13.718112</td>\n",
              "      <td>10.863193</td>\n",
              "      <td>10.201102</td>\n",
              "      <td>11.201539</td>\n",
              "      <td>12.935112</td>\n",
              "      <td>12.101972</td>\n",
              "      <td>11.384756</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>259</th>\n",
              "      <td>TCGA-24-1418</td>\n",
              "      <td>training</td>\n",
              "      <td>1</td>\n",
              "      <td>11.179123</td>\n",
              "      <td>10.030710</td>\n",
              "      <td>11.754480</td>\n",
              "      <td>9.890963</td>\n",
              "      <td>5.053992</td>\n",
              "      <td>14.991673</td>\n",
              "      <td>10.565480</td>\n",
              "      <td>12.558499</td>\n",
              "      <td>12.146200</td>\n",
              "      <td>9.668121</td>\n",
              "      <td>10.706535</td>\n",
              "      <td>10.394506</td>\n",
              "      <td>10.503950</td>\n",
              "      <td>12.334730</td>\n",
              "      <td>14.210613</td>\n",
              "      <td>12.460933</td>\n",
              "      <td>11.495057</td>\n",
              "      <td>12.223316</td>\n",
              "      <td>13.291306</td>\n",
              "      <td>9.452475</td>\n",
              "      <td>13.491247</td>\n",
              "      <td>16.061199</td>\n",
              "      <td>12.215986</td>\n",
              "      <td>10.854387</td>\n",
              "      <td>9.764404</td>\n",
              "      <td>12.818093</td>\n",
              "      <td>13.071414</td>\n",
              "      <td>10.605887</td>\n",
              "      <td>9.015512</td>\n",
              "      <td>9.149569</td>\n",
              "      <td>11.744812</td>\n",
              "      <td>12.078673</td>\n",
              "      <td>11.271800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>260</th>\n",
              "      <td>TCGA-36-1576</td>\n",
              "      <td>training</td>\n",
              "      <td>1</td>\n",
              "      <td>11.655380</td>\n",
              "      <td>10.032751</td>\n",
              "      <td>12.059854</td>\n",
              "      <td>10.290936</td>\n",
              "      <td>5.240370</td>\n",
              "      <td>14.219227</td>\n",
              "      <td>10.592819</td>\n",
              "      <td>12.357946</td>\n",
              "      <td>11.837887</td>\n",
              "      <td>10.792815</td>\n",
              "      <td>11.876288</td>\n",
              "      <td>9.877489</td>\n",
              "      <td>10.436339</td>\n",
              "      <td>13.053486</td>\n",
              "      <td>14.257058</td>\n",
              "      <td>12.432225</td>\n",
              "      <td>12.485092</td>\n",
              "      <td>13.489722</td>\n",
              "      <td>11.128625</td>\n",
              "      <td>10.160496</td>\n",
              "      <td>13.924804</td>\n",
              "      <td>15.779136</td>\n",
              "      <td>12.684473</td>\n",
              "      <td>11.004037</td>\n",
              "      <td>9.652130</td>\n",
              "      <td>12.400591</td>\n",
              "      <td>13.213521</td>\n",
              "      <td>11.858550</td>\n",
              "      <td>9.651770</td>\n",
              "      <td>11.846926</td>\n",
              "      <td>12.634752</td>\n",
              "      <td>11.738259</td>\n",
              "      <td>11.254909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>261</th>\n",
              "      <td>TCGA-24-2290</td>\n",
              "      <td>training</td>\n",
              "      <td>1</td>\n",
              "      <td>11.517504</td>\n",
              "      <td>10.191245</td>\n",
              "      <td>12.552382</td>\n",
              "      <td>11.060430</td>\n",
              "      <td>6.843453</td>\n",
              "      <td>14.193186</td>\n",
              "      <td>11.223297</td>\n",
              "      <td>12.373880</td>\n",
              "      <td>9.943035</td>\n",
              "      <td>10.125776</td>\n",
              "      <td>10.684256</td>\n",
              "      <td>9.115061</td>\n",
              "      <td>11.350987</td>\n",
              "      <td>12.533298</td>\n",
              "      <td>12.417001</td>\n",
              "      <td>12.476885</td>\n",
              "      <td>9.791050</td>\n",
              "      <td>10.038397</td>\n",
              "      <td>13.737365</td>\n",
              "      <td>10.590630</td>\n",
              "      <td>12.815252</td>\n",
              "      <td>15.743162</td>\n",
              "      <td>12.895449</td>\n",
              "      <td>11.982601</td>\n",
              "      <td>9.504284</td>\n",
              "      <td>13.286975</td>\n",
              "      <td>12.378044</td>\n",
              "      <td>11.070276</td>\n",
              "      <td>8.722501</td>\n",
              "      <td>7.861902</td>\n",
              "      <td>10.515498</td>\n",
              "      <td>11.807454</td>\n",
              "      <td>11.819364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>262</th>\n",
              "      <td>TCGA-24-1563</td>\n",
              "      <td>training</td>\n",
              "      <td>1</td>\n",
              "      <td>11.595700</td>\n",
              "      <td>9.381507</td>\n",
              "      <td>12.383145</td>\n",
              "      <td>9.477424</td>\n",
              "      <td>6.052465</td>\n",
              "      <td>14.900644</td>\n",
              "      <td>11.146321</td>\n",
              "      <td>12.339813</td>\n",
              "      <td>12.194963</td>\n",
              "      <td>10.752415</td>\n",
              "      <td>12.020596</td>\n",
              "      <td>10.462295</td>\n",
              "      <td>10.992227</td>\n",
              "      <td>12.784387</td>\n",
              "      <td>14.123139</td>\n",
              "      <td>12.431182</td>\n",
              "      <td>12.406281</td>\n",
              "      <td>12.340340</td>\n",
              "      <td>8.871656</td>\n",
              "      <td>10.151962</td>\n",
              "      <td>13.952942</td>\n",
              "      <td>15.877573</td>\n",
              "      <td>12.726649</td>\n",
              "      <td>11.336160</td>\n",
              "      <td>9.163516</td>\n",
              "      <td>12.527071</td>\n",
              "      <td>12.865786</td>\n",
              "      <td>11.090034</td>\n",
              "      <td>9.497262</td>\n",
              "      <td>11.940572</td>\n",
              "      <td>12.592379</td>\n",
              "      <td>11.515596</td>\n",
              "      <td>10.891493</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>263</th>\n",
              "      <td>TCGA-24-0979</td>\n",
              "      <td>training</td>\n",
              "      <td>1</td>\n",
              "      <td>11.725627</td>\n",
              "      <td>9.732958</td>\n",
              "      <td>12.967748</td>\n",
              "      <td>9.994073</td>\n",
              "      <td>5.845832</td>\n",
              "      <td>15.485416</td>\n",
              "      <td>9.914678</td>\n",
              "      <td>12.578045</td>\n",
              "      <td>9.709917</td>\n",
              "      <td>10.792189</td>\n",
              "      <td>10.027958</td>\n",
              "      <td>9.946368</td>\n",
              "      <td>11.362682</td>\n",
              "      <td>12.285667</td>\n",
              "      <td>12.214516</td>\n",
              "      <td>12.450841</td>\n",
              "      <td>6.689955</td>\n",
              "      <td>9.708911</td>\n",
              "      <td>11.116375</td>\n",
              "      <td>11.370592</td>\n",
              "      <td>11.839679</td>\n",
              "      <td>16.866923</td>\n",
              "      <td>12.500928</td>\n",
              "      <td>11.032033</td>\n",
              "      <td>8.811407</td>\n",
              "      <td>12.582286</td>\n",
              "      <td>12.314588</td>\n",
              "      <td>10.808727</td>\n",
              "      <td>8.968614</td>\n",
              "      <td>5.227241</td>\n",
              "      <td>10.339434</td>\n",
              "      <td>11.855478</td>\n",
              "      <td>10.706438</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>264 rows × 36 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           sample data_partition  label  ...      COPZ2       TRIO       PDPR\n",
              "0    TCGA-25-2399        testing      0  ...  11.506841  12.260439  11.589751\n",
              "1    TCGA-36-1569        testing      0  ...  12.154511  12.212926  11.787660\n",
              "2    TCGA-25-1316        testing      0  ...  10.488821  11.567196  11.550038\n",
              "3    TCGA-23-1109        testing      0  ...  12.222601  11.504207  11.931388\n",
              "4    TCGA-24-2293        testing      0  ...  12.935112  12.101972  11.384756\n",
              "..            ...            ...    ...  ...        ...        ...        ...\n",
              "259  TCGA-24-1418       training      1  ...  11.744812  12.078673  11.271800\n",
              "260  TCGA-36-1576       training      1  ...  12.634752  11.738259  11.254909\n",
              "261  TCGA-24-2290       training      1  ...  10.515498  11.807454  11.819364\n",
              "262  TCGA-24-1563       training      1  ...  12.592379  11.515596  10.891493\n",
              "263  TCGA-24-0979       training      1  ...  10.339434  11.855478  10.706438\n",
              "\n",
              "[264 rows x 36 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGwsw_XlESNT"
      },
      "source": [
        "# Train the Machine Learning Model\n",
        "\n",
        "Now we can train a classifier using BigQuery ML with the data stored in the subset table. This model will be stored in the location specified by the \"bq_ml_model\" variable, and can be reused to predict samples in the future.\n",
        "\n",
        "We pass three options to the BQ ML model: model_type, auto_class_weights, and input_label_cols. Model_type specifies the classifier model type. In this case, we use \"LOGISTIC_REG\" to train a logistic regression classifier. Other classifier options are documented [here](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-create). Auto_class_weights indicates whether samples should be weighted to balance the classes. For example, if the dataset happens to have more samples labeled as \"Complete Response\", those samples would be less weighted to ensure that the model is not biased towards predicting those samples. Input_label_cols tells BigQuery that the \"label\" column should be used to determine each sample's label. \n",
        "\n",
        "**Warning**: BigQuery ML models can be very time-consuming and expensive to train. Please check your data size before running BigQuery ML commands. Information about BigQuery ML costs can be found [here](https://cloud.google.com/bigquery-ml/pricing)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C45GxlQvBg_l",
        "outputId": "c50bef55-52ad-45f6-de72-b5ba770a46b1"
      },
      "source": [
        "# create ML model using BigQuery\n",
        "ml_model_query = client.query((\"\"\"\n",
        "  CREATE OR REPLACE MODEL `{bq_project}.{bq_dataset}.{bq_ml_model}`\n",
        "  OPTIONS\n",
        "    (\n",
        "      model_type='LOGISTIC_REG',\n",
        "      auto_class_weights=TRUE,\n",
        "      input_label_cols=['label']\n",
        "    ) AS\n",
        "  SELECT * EXCEPT(sample, data_partition)  -- when training, we only the labels and feature columns\n",
        "  FROM `{bq_project}.{bq_dataset}.{bq_tmp_table}`\n",
        "  WHERE data_partition = 'training' -- using training data only\n",
        "\"\"\").format(\n",
        "  bq_project=bq_project,\n",
        "  bq_dataset=bq_dataset,\n",
        "  bq_ml_model=bq_ml_model,\n",
        "  bq_tmp_table=bq_tmp_table\n",
        ")).result()\n",
        "print(ml_model_query)\n",
        "\n",
        "# now get the model metadata\n",
        "ml_model = client.get_model('{}.{}.{}'.format(bq_project, bq_dataset, bq_ml_model))\n",
        "print(ml_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<google.cloud.bigquery.table._EmptyRowIterator object at 0x7f3893663810>\n",
            "Model(reference=ModelReference(project='isb-project-zero', dataset_id='jhp_scratch', project_id='tcga_ov_therapy_ml_lr_model'))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGToji8REVsL"
      },
      "source": [
        "# Evaluate the Machine Learning Model\n",
        "Once the model has been trained and stored, we can evaluate the model's performance using the \"testing\" dataset from our subset table. Evaluating a BQ ML model is generally less expensive than training. \n",
        "\n",
        "Use the following query to evaluate the BQ ML model. Note that we're using the \"data_partition = 'testing'\" clause to ensure that we're only evaluating the model with test samples from the subset table.  \n",
        "\n",
        "BigQuery's ML.EVALUATE function returns several performance metrics: precision, recall, accuracy, f1_score, log_loss, and roc_auc. More details about these performance metrics are available from [Google's ML Crash Course](https://developers.google.com/machine-learning/crash-course/classification/video-lecture). Specific topics can be found at the following URLs: [precision and recall](https://developers.google.com/machine-learning/crash-course/classification/precision-and-recall), [accuracy](https://developers.google.com/machine-learning/crash-course/classification/accuracy), [ROC and AUC](https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKqETMRvD1pS"
      },
      "source": [
        "ml_eval = client.query((\"\"\"\n",
        "SELECT * FROM ML.EVALUATE (MODEL `{bq_project}.{bq_dataset}.{bq_ml_model}`, \n",
        "  (\n",
        "    SELECT * EXCEPT(sample, data_partition)\n",
        "    FROM `{bq_project}.{bq_dataset}.{bq_tmp_table}`\n",
        "    WHERE data_partition = 'testing'\n",
        "  )\n",
        ")\n",
        "\"\"\").format(\n",
        "  bq_project=bq_project,\n",
        "  bq_dataset=bq_dataset,\n",
        "  bq_ml_model=bq_ml_model,\n",
        "  bq_tmp_table=bq_tmp_table\n",
        ")).result().to_dataframe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "qakC4kcgEdQL",
        "outputId": "dad24bde-f5ce-4e68-f190-d8d60aa7237f"
      },
      "source": [
        "# Display the table of evaluation results\n",
        "ml_eval"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1_score</th>\n",
              "      <th>log_loss</th>\n",
              "      <th>roc_auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.753425</td>\n",
              "      <td>0.639535</td>\n",
              "      <td>0.623077</td>\n",
              "      <td>0.691824</td>\n",
              "      <td>0.681854</td>\n",
              "      <td>0.680869</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   precision    recall  accuracy  f1_score  log_loss   roc_auc\n",
              "0   0.753425  0.639535  0.623077  0.691824  0.681854  0.680869"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMqUJWfghyVg"
      },
      "source": [
        "# Predict Outcome for One or More Samples\n",
        "ML.EVALUATE evaluates a model's performance, but does not produce actual predictions for each sample. In order to do that, we need to use the ML.PREDICT function. The syntax is similar to that of the ML.EVALUATE function and returns \"label\", \"predicted_label\", \"predicted_label_probs\", and all feature columns. Since the feature columns are unchanged from the input dataset, we select only the original label, predicted label, and probabilities for each sample. \n",
        "\n",
        "Note that the input dataset can include one or more samples, and must include the same set of features as the training dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlqVLWBqiKQs"
      },
      "source": [
        "ml_predict = client.query((\"\"\"\n",
        "SELECT\n",
        "  label,\n",
        "  predicted_label,\n",
        "  predicted_label_probs\n",
        "FROM ML.PREDICT (MODEL `{bq_project}.{bq_dataset}.{bq_ml_model}`, \n",
        "  (\n",
        "    SELECT * EXCEPT(sample, data_partition)\n",
        "    FROM `{bq_project}.{bq_dataset}.{bq_tmp_table}`\n",
        "    WHERE data_partition = 'testing' -- Use the testing dataset\n",
        "  )\n",
        ")\n",
        "\"\"\").format(\n",
        "  bq_project=bq_project,\n",
        "  bq_dataset=bq_dataset,\n",
        "  bq_ml_model=bq_ml_model,\n",
        "  bq_tmp_table=bq_tmp_table\n",
        ")).result().to_dataframe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "CA0PwTQLibN0",
        "outputId": "a3f5a31e-d39f-4b2b-da3b-3cae33df1b4c"
      },
      "source": [
        "# Display the table of prediction results\n",
        "ml_predict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>predicted_label</th>\n",
              "      <th>predicted_label_probs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[{'label': 1, 'prob': 0.8768811208292162}, {'l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[{'label': 1, 'prob': 0.10363196036093822}, {'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[{'label': 1, 'prob': 0.21867379546674287}, {'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[{'label': 1, 'prob': 0.8001977008015101}, {'l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[{'label': 1, 'prob': 0.08631178853125597}, {'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>[{'label': 1, 'prob': 0.37733292631578663}, {'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[{'label': 1, 'prob': 0.5500701258874308}, {'l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>[{'label': 1, 'prob': 0.1872213285324457}, {'l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>[{'label': 1, 'prob': 0.031385329936844904}, {...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[{'label': 1, 'prob': 0.8353130143781878}, {'l...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>130 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     label  predicted_label                              predicted_label_probs\n",
              "0        0                1  [{'label': 1, 'prob': 0.8768811208292162}, {'l...\n",
              "1        0                0  [{'label': 1, 'prob': 0.10363196036093822}, {'...\n",
              "2        0                0  [{'label': 1, 'prob': 0.21867379546674287}, {'...\n",
              "3        0                1  [{'label': 1, 'prob': 0.8001977008015101}, {'l...\n",
              "4        0                0  [{'label': 1, 'prob': 0.08631178853125597}, {'...\n",
              "..     ...              ...                                                ...\n",
              "125      1                0  [{'label': 1, 'prob': 0.37733292631578663}, {'...\n",
              "126      1                1  [{'label': 1, 'prob': 0.5500701258874308}, {'l...\n",
              "127      1                0  [{'label': 1, 'prob': 0.1872213285324457}, {'l...\n",
              "128      1                0  [{'label': 1, 'prob': 0.031385329936844904}, {...\n",
              "129      1                1  [{'label': 1, 'prob': 0.8353130143781878}, {'l...\n",
              "\n",
              "[130 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxVApa9_r7Sq",
        "outputId": "ad72a659-d2fb-46c2-b0b6-4d5c3f0edbcb"
      },
      "source": [
        "# Calculate the accuracy of prediction, which should match the result of ML.EVALUATE\n",
        "accuracy = 1-sum(abs(ml_predict['label']-ml_predict['predicted_label']))/len(ml_predict)\n",
        "print('Accuracy: ', accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.6230769230769231\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOGad8PVkFS6"
      },
      "source": [
        "# Next Steps\n",
        "The BigQuery ML logistic regression model trained in this notebook is comparable to the scikit-learn model developed in our [companion notebook](https://github.com/isb-cgc/Community-Notebooks/blob/master/MachineLearning/How_to_build_an_RNAseq_logistic_regression_classifier.ipynb). BigQuery ML simplifies the model building and evaluation process by enabling bioinformaticians to use machine learning within the BigQuery ecosystem. However, it is often necessary to optimize performance by evaluating several types of models (i.e., other than logistic regression), and tuning model parameters. Due to the cost of BigQuery ML for training, such iterative model fine-tuning may be cost prohibitive. In such cases, a combination of scikit-learn (or other libraries such as Keras and TensorFlow) and BigQuery ML may be appropriate. E.g., models can be fine-tuned using scikit-learn and published as a BigQuery ML model for production applications. In future notebooks, we will explore methods for model selection, optimization, and publication with BigQuery ML. "
      ]
    }
  ]
}
